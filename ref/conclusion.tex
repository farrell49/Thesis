To enable a complex mobile manipulator to do useful work under operator guidance, a software system that ties together high-level modules, composed of other, lower-level components.
The core contribution of this paper is the development of the interaction between these modules, and the capabilities they should provide to accomplish complex tasks in an unstructured environment.
These modules were 
  \textbf{a)} the underlying robot that provides some guarantees of complaint motion,
  \textbf{b)} task and motion planning to generate feasible,
  \textbf{c)} object handling via computer vision and object-associated semantics,
  \textbf{d)} and a user interface for a user to specify both high- and low-level goals for the system.
The specific implementation presented was demonstrated within a archetypal logistics task in a mock-up space station, and shown to be efficient for many complex tasks.
These modules are largely robot-independent, with robot-specific implementation coming only into play at the task and motion planning layer, which can solve a wide variety of complex, constrained motion planning requests, streamlining the design of other modules within the system.

